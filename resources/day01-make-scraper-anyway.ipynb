{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, python!\n"
     ]
    }
   ],
   "source": [
    "print('hello, python!') # shift+enter 키로 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리 import 하기\n",
    "import requests # 리소스 접근을 위한 라이브러리\n",
    "import lxml # html parser\n",
    "from bs4 import BeautifulSoup # 실제 데이터를 추출하는 도구\n",
    "from time import ctime\n",
    "from openpyxl import load_workbook, Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 접속관련 처리를 하는 requests 라이브러리 알아보기\n",
    "# requests.get('주소') 로 해당 주소의 페이지에 접근합니다.\n",
    "# 그 결과물을 response 에 할당합니다.\n",
    "response = requests.get('https://www.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 접속 결과물의 텍스트값 출력하여 확인하기\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n사 실시간 검색어 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.naver.com')\n",
    "exec_time = ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = response.text\n",
    "soup = BeautifulSoup(html_text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_tag = soup.find('ul', attrs={'class':'ah_l'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_list = ul_tag.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sat Nov  9 20:55:25 2019',\n",
       " ['1', '놀라운 토요일'],\n",
       " ['2', '놀라운 토요일 도레미마켓'],\n",
       " ['3', '유피 바다'],\n",
       " ['4', '유쾌한 씨의 껌 씹는 방법'],\n",
       " ['5', '로드fc'],\n",
       " ['6', '백청강'],\n",
       " ['7', '권아솔'],\n",
       " ['8', '키'],\n",
       " ['9', '도레미마켓'],\n",
       " ['10', '변리사'],\n",
       " ['11', '공작'],\n",
       " ['12', '놀토 도레미마켓'],\n",
       " ['13', '놀토'],\n",
       " ['14', '김영철'],\n",
       " ['15', '김영철의 동네 한 바퀴'],\n",
       " ['16', '윤도현'],\n",
       " ['17', '샤이니 키 제대'],\n",
       " ['18', '로또 추첨시간'],\n",
       " ['19', '한해'],\n",
       " ['20', '유영']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [exec_time]\n",
    "for li in li_list:\n",
    "    rank = li.find('span', attrs={'class':'ah_r'}).text\n",
    "    keyword = li.find('span', attrs={'class':'ah_k'}).text\n",
    "    result.append([rank, keyword])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rottentomatoes Top Box Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rottentomatoes에 접속하고, 접속 당시의 시간을 기록합니다.\n",
    "response = requests.get('https://rottentomatoes.com/')\n",
    "exec_time = ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 접속결과물의 텍스트 값을 저장합니다.\n",
    "html_text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 값을 lxml과 BeautifulSoup을 활용하여 Parse 합니다.\n",
    "soup = BeautifulSoup(html_text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tag = soup.find('table', attrs={'id':'Top-Box-Office'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sat Nov  9 20:55:35 2019',\n",
       " [71,\n",
       "  'Terminator: Dark Fate',\n",
       "  29.1,\n",
       "  'https://rottentomatoes.com/m/terminator_dark_fate'],\n",
       " [69, 'Joker', 13.6, 'https://rottentomatoes.com/m/joker_2019'],\n",
       " [41,\n",
       "  'Maleficent: Mistress of Evil',\n",
       "  13.2,\n",
       "  'https://rottentomatoes.com/m/maleficent_mistress_of_evil'],\n",
       " [72, 'Harriet', 11.8, 'https://rottentomatoes.com/m/harriet'],\n",
       " [43,\n",
       "  'The Addams Family',\n",
       "  8.3,\n",
       "  'https://rottentomatoes.com/m/the_addams_family_2019'],\n",
       " [68,\n",
       "  'Zombieland: Double Tap',\n",
       "  7.5,\n",
       "  'https://rottentomatoes.com/m/zombieland_double_tap'],\n",
       " [23, 'Countdown', 5.8, 'https://rottentomatoes.com/m/countdown_2019'],\n",
       " [50,\n",
       "  'Black and Blue',\n",
       "  4.2,\n",
       "  'https://rottentomatoes.com/m/black_and_blue_2019'],\n",
       " [62,\n",
       "  'Motherless Brooklyn',\n",
       "  3.5,\n",
       "  'https://rottentomatoes.com/m/motherless_brooklyn'],\n",
       " [15, 'Arctic Dogs', 3.0, 'https://rottentomatoes.com/m/arctic_dogs']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tags = table_tag.find_all('tr')\n",
    "box_office = [exec_time]\n",
    "for tr in tr_tags:\n",
    "    all_as = tr.find_all('a')\n",
    "    score = all_as[0].find('span', attrs={'class':'tMeterScore'}).text\n",
    "    score = int(score.replace('%',''))\n",
    "    movie_name = all_as[1].text\n",
    "    revenue = all_as[2].text\n",
    "    revenue = float(revenue.replace('$','').replace('M',''))\n",
    "    link = \"https://rottentomatoes.com\" + all_as[2][\"href\"]\n",
    "    box_office.append([score, movie_name, revenue, link])\n",
    "box_office"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 값 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sat Nov  9 20:55:25 2019',\n",
       " ['1', '놀라운 토요일'],\n",
       " ['2', '놀라운 토요일 도레미마켓'],\n",
       " ['3', '유피 바다'],\n",
       " ['4', '유쾌한 씨의 껌 씹는 방법'],\n",
       " ['5', '로드fc'],\n",
       " ['6', '백청강'],\n",
       " ['7', '권아솔'],\n",
       " ['8', '키'],\n",
       " ['9', '도레미마켓'],\n",
       " ['10', '변리사'],\n",
       " ['11', '공작'],\n",
       " ['12', '놀토 도레미마켓'],\n",
       " ['13', '놀토'],\n",
       " ['14', '김영철'],\n",
       " ['15', '김영철의 동네 한 바퀴'],\n",
       " ['16', '윤도현'],\n",
       " ['17', '샤이니 키 제대'],\n",
       " ['18', '로또 추첨시간'],\n",
       " ['19', '한해'],\n",
       " ['20', '유영']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sat Nov  9 20:55:35 2019',\n",
       " [71,\n",
       "  'Terminator: Dark Fate',\n",
       "  29.1,\n",
       "  'https://rottentomatoes.com/m/terminator_dark_fate'],\n",
       " [69, 'Joker', 13.6, 'https://rottentomatoes.com/m/joker_2019'],\n",
       " [41,\n",
       "  'Maleficent: Mistress of Evil',\n",
       "  13.2,\n",
       "  'https://rottentomatoes.com/m/maleficent_mistress_of_evil'],\n",
       " [72, 'Harriet', 11.8, 'https://rottentomatoes.com/m/harriet'],\n",
       " [43,\n",
       "  'The Addams Family',\n",
       "  8.3,\n",
       "  'https://rottentomatoes.com/m/the_addams_family_2019'],\n",
       " [68,\n",
       "  'Zombieland: Double Tap',\n",
       "  7.5,\n",
       "  'https://rottentomatoes.com/m/zombieland_double_tap'],\n",
       " [23, 'Countdown', 5.8, 'https://rottentomatoes.com/m/countdown_2019'],\n",
       " [50,\n",
       "  'Black and Blue',\n",
       "  4.2,\n",
       "  'https://rottentomatoes.com/m/black_and_blue_2019'],\n",
       " [62,\n",
       "  'Motherless Brooklyn',\n",
       "  3.5,\n",
       "  'https://rottentomatoes.com/m/motherless_brooklyn'],\n",
       " [15, 'Arctic Dogs', 3.0, 'https://rottentomatoes.com/m/arctic_dogs']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt 포맷으로 저장하기\n",
    "with open('nv_query.txt', 'w') as f:\n",
    "    for item in result[1:]:\n",
    "        f.write(\"{}위는 {}입니다.\\n\".format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위는 소방의날세이퍼스입니다.\n",
      "\n",
      "2위는 임창정입니다.\n",
      "\n",
      "3위는 숨바꼭질입니다.\n",
      "\n",
      "4위는 임창정 아내입니다.\n",
      "\n",
      "5위는 세이퍼스입니다.\n",
      "\n",
      "6위는 선우은숙입니다.\n",
      "\n",
      "7위는 안시성입니다.\n",
      "\n",
      "8위는 영화 숨바꼭질입니다.\n",
      "\n",
      "9위는 알토란 작가 고은정입니다.\n",
      "\n",
      "10위는 로드fc입니다.\n",
      "\n",
      "11위는 이영하선우은숙입니다.\n",
      "\n",
      "12위는 산수시 데포세럼입니다.\n",
      "\n",
      "13위는 박홍입니다.\n",
      "\n",
      "14위는 김승현 여자친구입니다.\n",
      "\n",
      "15위는 알토란입니다.\n",
      "\n",
      "16위는 구강세정기입니다.\n",
      "\n",
      "17위는 이마트앱퀴즈입니다.\n",
      "\n",
      "18위는 송은이표 강조입니다.\n",
      "\n",
      "19위는 김승현입니다.\n",
      "\n",
      "20위는 김성은입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('nv_query.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for item in lines:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 형식으로 저장하기 - old(excel로 열 경우 인코딩 안맞음)\n",
    "with open('nv_querys.csv', 'w') as f:\n",
    "    for item in result[1:]:\n",
    "        f.write(\"{},{},{}\\n\".format(result[0], item[0], item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  9 15:14:02 2019,1,소방의날세이퍼스\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,2,임창정\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,3,숨바꼭질\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,4,임창정 아내\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,5,세이퍼스\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,6,선우은숙\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,7,안시성\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,8,영화 숨바꼭질\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,9,알토란 작가 고은정\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,10,로드fc\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,11,이영하선우은숙\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,12,산수시 데포세럼\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,13,박홍\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,14,김승현 여자친구\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,15,알토란\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,16,구강세정기\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,17,이마트앱퀴즈\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,18,송은이표 강조\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,19,김승현\n",
      "\n",
      "Sat Nov  9 15:14:02 2019,20,김성은\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('nv_querys.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for item in lines:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 형식으로 저장하기(new: unicode를 utf-8-sig 형식으로 바꾸어 엑셀에서도 인코딩 인식이 가능하게 설정)\n",
    "import csv\n",
    "\n",
    "\n",
    "with open('nv_query_utf8.csv', 'w', encoding='utf-8-sig', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for item in result[1:]:\n",
    "        writer.writerow([result[0], item[0], item[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel로 저장하기\n",
    "workbook_name = 'nv_querys.xlsx'\n",
    "try:\n",
    "    workbook = load_workbook(workbook_name)\n",
    "except FileNotFoundError as e:\n",
    "    workbook = Workbook()\n",
    "worksheet = workbook.active\n",
    "for item in result[1:]:\n",
    "    worksheet.append([result[0], item[0], item[1]])\n",
    "workbook.save(workbook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 형식으로 저장하기\n",
    "import json\n",
    "\n",
    "\n",
    "nv_object = {'date': result[0], 'items': dict(result[1:])}\n",
    "try:\n",
    "    with open('nv_query.json', 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        data[\"data\"].append(nv_object)\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.truncate()\n",
    "except:\n",
    "    with open('nv_query.json', 'w') as f:\n",
    "        json.dump({'data':[nv_object]}, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "json 데이터의 저장 형태\n",
    "{\n",
    "    'data':[\n",
    "        {\n",
    "            'date':'',\n",
    "            'items':{'1':'', '2':'', ..}\n",
    "        },\n",
    "        {\n",
    "            'date':'',\n",
    "            'items':{'1':'', '2':'', ..}\n",
    "        },\n",
    "        {\n",
    "            'date':'',\n",
    "            'items':{'1':'', '2':'', ..}\n",
    "        },\n",
    "        {\n",
    "            'date':'',\n",
    "            'items':{'1':'', '2':'', ..}\n",
    "        },\n",
    "        {\n",
    "            'date':'',\n",
    "            'items':{'1':'', '2':'', ..}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
